{"cells":[{"cell_type":"markdown","metadata":{"id":"msybrHwl6YRN"},"source":["Github code from authors stored in picrispr-main\n","\n","TODO:\n","\n","1. Preprocess data (dir is offtarget_260520_nuc.csv.zip (crisprsql dataset)).\n","we can use the code from load_data.py and encoding.py.\n","the author calls the functions from those classes in picrispr.py.\n","\n","2. Run models (models.py)\n","\n","3. Test model (test_input.csv)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1022,"status":"ok","timestamp":1702329687936,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"},"user_tz":300},"id":"-w5DqljseUdP","outputId":"a47675bd-d4ae-4a8e-f2c0-65dde527c4d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","/content/gdrive/.shortcut-targets-by-id/1xWx4iaOa4dZLKNbO8SfeXGyQyzJoKG1L/piCrispr2.0/picrispr-main\n"," default_vals   nontransformed.png\t      'picrispr data format.gsheet'   test_input.csv\n"," encoding.py    offtarget_260520_nuc.csv.zip   picrispr.py\t\t      transformedback.png\n"," load_data.py  'output(1).gsheet'\t       __pycache__\t\t     'WillB (1).py'\n"," models         output.csv\t\t       README.md\t\t      WillB.py\n"," models.py      output_Option3RNN.csv\t       requirements.txt\n"]}],"source":["#Load files\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/.shortcut-targets-by-id/1xWx4iaOa4dZLKNbO8SfeXGyQyzJoKG1L/piCrispr2.0/picrispr-main\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51497,"status":"ok","timestamp":1702081100990,"user":{"displayName":"Jonathan Dou","userId":"05800810679780924235"},"user_tz":300},"id":"z4zFdmxun4iU","outputId":"f82369b7-3af1-428b-83b7-4dacfe177fac"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf _s4 __________________________________\n","2it [00:00, 9974.56it/s]\n","839it [00:00, 17190.11it/s]\n","2it [00:00, 11366.68it/s]\n","61it [00:00, 17428.65it/s]\n","74it [00:00, 26234.34it/s]\n","22it [00:00, 21917.98it/s]\n","/content/gdrive/.shortcut-targets-by-id/1xWx4iaOa4dZLKNbO8SfeXGyQyzJoKG1L/piCrispr2.0/picrispr-main/picrispr.py:593: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)\n","  return sparse_tensortype(indices, values, x.size())\n","using GPU device Tesla T4\n","done\n","config[mode] is  tf  so dm.mode was set to be  tf\n","loading model...load function was passed  tf  for mode\n","done\n","preparing dataset...done\n","obtaining predictions...\n","32/32 [==============================] - 8s 237ms/step\n","successfully saved predictions to output.csv\n"]}],"source":["\n","\n","#!python WillB.py test_input.csv 3\n","!python picrispr.py test_input.csv 2 models False False\n","#picrispr.py 588 throw no such file or directory when running torch models\n","#Searches for 'models/trainresult_torch_interface_type_s2_class.pickle'\n","#Directory has 'models/trainresult_tf_interface_type_s2_class.pickle'\n","#Forcing torch version to look for tf file instead gives error... (screenshot2) and (screenshot4) if mode is changed in load function\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":156,"status":"ok","timestamp":1702328951932,"user":{"displayName":"Jonathan Dou","userId":"05800810679780924235"},"user_tz":300},"id":"V-Ds2S-Y6Xkg","outputId":"d8770759-973a-4eb1-8da4-af62be0e8a57"},"outputs":[{"output_type":"stream","name":"stdout","text":[" default_vals   nontransformed.png\t      'picrispr data format.gsheet'   test_input.csv\n"," encoding.py    offtarget_260520_nuc.csv.zip   picrispr.py\t\t      transformedback.png\n"," load_data.py  'output(1).gsheet'\t       __pycache__\t\t     'WillB (1).py'\n"," models         output.csv\t\t       README.md\t\t      WillB.py\n"," models.py      output_Option3RNN.csv\t       requirements.txt\n"]}],"source":["\n","!ls\n","#load data preproces here"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14086,"status":"ok","timestamp":1702329954798,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"},"user_tz":300},"id":"R_M9-mAkqCCR","outputId":"e6a177c4-7a28-4bdb-a2c9-74c27ce74bc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['id', 'experiment_id', 'target_chr', 'target_start', 'target_end',\n","       'target_strand', 'target_sequence', 'target_context', 'target_geneid',\n","       'grna_target_id', 'grna_target_chr', 'grna_target_start',\n","       'grna_target_end', 'grna_target_strand', 'grna_target_sequence',\n","       'genome', 'cell_line', 'measured', 'cleavage_freq', 'epigenetics_ids',\n","       'epigen_ctcf', 'epigen_dnase', 'epigen_rrbs', 'epigen_h3k4me3',\n","       'epigen_drip', 'energy_1', 'energy_2', 'energy_3', 'energy_4',\n","       'energy_5', 'GCContent', 'WSScore', 'YRScore', 'NucleotideBDM',\n","       'StrongWeakBDM', 'NuPoP_Occup_147_human', 'NuPoP_Viterbi_147_human',\n","       'NuPoP_Affinity_147_human', 'nuCpos_Occup_147_yeast',\n","       'nuCpos_Viterbi_147_yeast', 'nuCpos_Affinity_147_yeast',\n","       'VanDerHeijden', 'LeNupH3Q85C', 'mismatch_num',\n","       'energy_4*(energy_3/energy_2)', 'energy_2-energy_4*(energy_3/energy_2)',\n","       'energy_1-energy_4*(energy_3/energy_2)'],\n","      dtype='object')\n"]}],"source":["import pandas as pd\n","filePath = \"offtarget_260520_nuc.csv.zip\"\n","df = pd.read_csv(filePath, low_memory=False)\n","print(df.columns)"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Q9M7N-r_qXog","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702330902462,"user_tz":300,"elapsed":56406,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}},"outputId":"458884b9-9d3c-4425-9e5f-a027a46687b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'dbFields': 'target_sequence, grna_target_sequence, NucleotideBDM, NuPoP_Affinity_147_human, GCContent, energy_2+energy_1-(energy_3*energy_4/energy_2), experiment_id', 'numBpWise': 3, 'mode': 'tf', 'mismatchType': False, 'interfaceMode': False, 'chooseSpecies': ['hg19', 'hg38'], 'regression': False, 'CRISPRNetStyle': True}\n","tf _s4 __________________________________\n","encoding dataset..."]},{"output_type":"stream","name":"stderr","text":["103it [00:00, 8437.76it/s]\n","1505it [00:00, 9942.21it/s] \n","78it [00:00, 17068.70it/s]\n","3801it [00:00, 9988.04it/s] \n","51it [00:00, 7358.68it/s]\n","5413it [00:00, 11071.02it/s]\n","549it [00:00, 13329.43it/s]\n","44624it [00:03, 11220.45it/s]\n","72it [00:00, 6542.10it/s]\n","29327it [00:03, 8304.64it/s]\n","7374it [00:00, 8344.95it/s]\n","41429it [00:03, 10365.48it/s]\n","866it [00:00, 9920.87it/s]\n","6386it [00:00, 10372.98it/s]\n","231it [00:00, 10391.85it/s]\n","27995it [00:02, 10941.55it/s]\n","11it [00:00, 8670.80it/s]\n","2380it [00:00, 10583.59it/s]\n","86it [00:00, 9042.62it/s]\n","2438it [00:00, 9654.75it/s]\n","108it [00:00, 10124.38it/s]\n","3258it [00:00, 11753.11it/s]\n","61it [00:00, 5780.41it/s]\n","1747it [00:00, 10732.37it/s]\n","272it [00:00, 10292.03it/s]\n","23463it [00:02, 11714.43it/s]\n","203it [00:00, 11236.03it/s]\n","12373it [00:01, 8446.86it/s]\n","23it [00:00, 6379.38it/s]\n","21519it [00:02, 8617.57it/s]\n","11213it [00:00, 17040.80it/s]\n","2895it [00:00, 13356.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["using GPU device Tesla T4\n","done\n","config[mode] is  tf  so dm.mode was set to be  tf\n","loading model...done\n","preparing dataset..."]}],"source":["\n","\n","import sys\n","from encoding import oneHotSingleNuclTargetMismatchType, oneHotSingleNuclTargetMismatch, oneHotSingleNucl, normaliseCF\n","from models import mySequential, vecToMatEncoder, vecToMatEncoding\n","import pickle\n","from tqdm import tqdm\n","import xgboost as xgb\n","import torch\n","import tensorflow as tf\n","from scipy.stats import spearmanr\n","import os\n","os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n","from picrispr import CSVDataset\n","\n","\n","use_gpu = True\n","\n","filenames = [\"xgboost_interface_type_epi\", \"torch_eng\", \"torch_engnuc\", \"torch_interface_type_nuc\", \"tf_eng\", \"tf_engnuc\"]\n","modelnames =[\"XGB_S3E2\", \"CNN_S2E0\", \"CNN_S4E0\", \"CNN_S5E2\", \"RNN_S2E3\", \"RNN_S4E3\"]\n","\n","# define models\n","seq_features = \"target_sequence, grna_target_sequence, \"\n","energy_features = \"energy_2+energy_1-(energy_3*energy_4/energy_2), \"\n","epigen_features = \"epigen_ctcf, epigen_dnase, epigen_rrbs, epigen_h3k4me3, epigen_drip, \"\n","nuc_features = \"NucleotideBDM, NuPoP_Affinity_147_human, GCContent, \"\n","numBpWise = 3\n","\n","seq_energy_feat         = seq_features + energy_features + \"experiment_id\"\n","seq_energy_epi_feat     = seq_features + energy_features + epigen_features + \"experiment_id\"\n","seq_energy_nuc_feat     = seq_features + nuc_features + energy_features + \"experiment_id\"\n","seq_energy_epi_nuc_feat = seq_features + nuc_features + energy_features + epigen_features + \"experiment_id\"\n","\n","# retrieve user input\n","filePath = \"offtarget_260520_nuc.csv.zip\"\n","modelNum   = 2\n","home       = \"models\"\n","regression = False\n","replace_all_nans = False\n","\n","args = [(\"\", home, \"torch\", False, regression, \"s4\", False), # E3+CRISPRNetStyle, CNN, s4\n","        (\"\", home, \"torch\", False, regression, \"s2\", False), # E3+CRISPRNetStyle, CNN, s2\n","        (\"\", home, \"tf\",    False, regression, \"s4\", False), # E3+CRISPRNetStyle, RNN, s4\n","        (\"\", home, \"tf\",    False, regression, \"s2\", False), # E3+CRISPRNetStyle, RNN, s2\n","        (\"\", home, \"torch\", True,  regression, \"s4\", True),  # E2,                CNN, s4\n","        (\"\", home, \"torch\", True,  regression, \"s2\", True),  # E2,                CNN, s2\n","        (\"\", home, \"tf\",    True,  regression, \"s4\", True),  # E2,                RNN, s4\n","        (\"\", home, \"tf\",    True,  regression, \"s2\", True),  # E2,                RNN, s2\n","        ]\n","\n","kwargs = [{'dbFields': seq_energy_nuc_feat, 'numBpWise': numBpWise, 'CRISPRNetStyle': True},\n","          {'dbFields': seq_energy_feat,     'numBpWise': 0,         'CRISPRNetStyle': True},\n","          {'dbFields': seq_energy_nuc_feat, 'numBpWise': numBpWise, 'CRISPRNetStyle': True},\n","          {'dbFields': seq_energy_feat,     'numBpWise': 0,         'CRISPRNetStyle': True},\n","          {'dbFields': seq_energy_nuc_feat, 'numBpWise': numBpWise, 'CRISPRNetStyle': False},\n","          {'dbFields': seq_energy_feat,     'numBpWise': 0,         'CRISPRNetStyle': False},\n","          {'dbFields': seq_energy_nuc_feat, 'numBpWise': numBpWise, 'CRISPRNetStyle': False},\n","          {'dbFields': seq_energy_feat,     'numBpWise': 0,         'CRISPRNetStyle': False}\n","          ]\n","\n","# load user dataset and chosen model\n","dataset = CSVDataset(filePath)\n","\n","config = {\"dbFields\": kwargs[modelNum]['dbFields'],\n","          \"numBpWise\": kwargs[modelNum]['numBpWise'],\n","          \"mode\": args[modelNum][2],\n","          \"mismatchType\": args[modelNum][3],\n","          \"interfaceMode\": args[modelNum][6],\n","          \"chooseSpecies\": [\"hg19\", \"hg38\"],\n","          \"regression\": args[modelNum][4],\n","          \"CRISPRNetStyle\": kwargs[modelNum]['CRISPRNetStyle'],\n","          }\n","\n","print(config)\n","\n","filenameAppendix  = \"_interface\" if config[\"interfaceMode\"] else \"\"\n","filenameAppendix += \"_type\"      if config[\"mismatchType\"] and config[\"interfaceMode\"]  else \"\"\n","filenameAppendix += \"_\"+args[modelNum][5]\n","\n","print(config[\"mode\"], filenameAppendix, \"__________________________________\")\n","\n","if config[\"mismatchType\"]:\n","    oneHotFct = oneHotSingleNuclTargetMismatchType\n","    featurenames = ['A_match', 'T_match', 'C_match', 'G_match',\n","                    'A_mismT', 'T_mismC', 'C_mismG', 'G_mismA',\n","                    'A_mismC', 'T_mismG', 'C_mismA', 'G_mismT',\n","                    'A_mismG', 'T_mismA', 'C_mismT', 'G_mismC']\n","elif config[\"interfaceMode\"]:\n","    oneHotFct = oneHotSingleNuclTargetMismatch\n","    featurenames = ['A', 'A_mism', 'T', 'T_mism', 'C', 'C_mism', 'G', 'G_mism']\n","else:\n","    oneHotFct = oneHotSingleNucl\n","    featurenames = ['A',           'T',           'C',           'G']\n","\n","featurenames.extend(\" \".join(config[\"dbFields\"].split()).split(', ')[2:]) # append whatever database fields apart from guide and target sequence are used\n","\n","\n","# get data matrix from user input\n","filenameAppendix += \"_class\" if not config[\"regression\"] else \"\"\n","\n","print(\"encoding dataset...\", end = '')\n","dm = dataset.getDataMatrix(config[\"dbFields\"], oneHotFct, normaliseCF, chooseSpecies=config[\"chooseSpecies\"], filenameAppendix=filenameAppendix,\n","                            featurenames=featurenames, mode=config[\"mode\"], numBpWise=config[\"numBpWise\"], test_size=0.2, doSplit=True,\n","                            CRISPRNetStyle=config[\"CRISPRNetStyle\"], replace_all_nans=replace_all_nans)\n","print(\"done\")\n","\n","print(\"config[mode] is \", config[\"mode\"], \" so dm.mode was set to be \", dm.mode)\n","dm.mode = config[\"mode\"]\n","dm.interfaceMode = config[\"interfaceMode\"]\n","dm.mismatchType = config[\"mismatchType\"]\n","dm.regression = config[\"regression\"]\n","dm.CRISPRNetStyle = config[\"CRISPRNetStyle\"]\n","\n","# load model\n","print(\"loading model...\", end = '')\n","#result = TrainResult.load(home, config[\"mode\"], filenameAppendix, device=\"gpu:0\" if use_gpu else \"cpu\")\n","print(\"done\")\n","\n","# predict on ext set\n","isHPC = True\n","#bs = int(7e4) if isHPC or dm.mode != \"torch\" else 35000\n","bs = 1024\n","# don't use experiment_id column\n","dm.toDense()\n","dm = dm.dropColumn(-1)\n","\n","print(\"preparing dataset...\", end = '')\n","trainDataset, validDataset, extDataset = dm.prepareDataset(cutoff_class=-4, addGaussian=False)\n","#trainDataset = PaddedDataset(trainDataset, desired_length)\n","#validDataset = PaddedDataset(validDataset, desired_length)\n","#extDataset = PaddedDataset(extDataset, desired_length)\n","#dm.prepareDataloaders(trainDataset, validDataset, extDataset, bs, balanceClasses=False, ignoreExtSet=True, doSampling=False)\n","#print(\"done\")"]},{"cell_type":"code","source":["l0 = []\n","l1 = []\n","\n","for batch in trainDataset:\n","    input, target, extra = batch\n","    if target.item() == 0:\n","      l0.append((input, target))\n","    else:\n","      l1.append((input, target))\n","\n","1-0.9155954378058586"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cu5Ljuwu8hn5","executionInfo":{"status":"ok","timestamp":1702330916449,"user_tz":300,"elapsed":3911,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}},"outputId":"0b87f14f-0da0-449b-e530-f75b4f28f826"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.08440456219414139"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["print(len(l0))\n","print(len(l1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rjwp7juL8jD7","executionInfo":{"status":"ok","timestamp":1702329019128,"user_tz":300,"elapsed":11,"user":{"displayName":"Jonathan Dou","userId":"05800810679780924235"}},"outputId":"6a8702a6-d222-4bd6-904a-1c69bd032743"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["184478\n","17004\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","l0 = np.array(l0)\n","l1 = np.array(l1)\n","np.random.shuffle(l0)\n","\n","l0 = l0[:len(l1)]\n","\n","l = np.concatenate((l0, l1))\n","\n","np.random.shuffle(l)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUVQ1cJ981-I","executionInfo":{"status":"ok","timestamp":1702330919722,"user_tz":300,"elapsed":3128,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}},"outputId":"54ecc098-4349-4f5e-9dc5-3efb50639e2f"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-20-6ce3c8c4995c>:3: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  l0 = np.array(l0)\n","<ipython-input-20-6ce3c8c4995c>:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  l0 = np.array(l0)\n","<ipython-input-20-6ce3c8c4995c>:4: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n","  l1 = np.array(l1)\n","<ipython-input-20-6ce3c8c4995c>:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  l1 = np.array(l1)\n"]}]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class MyDataset(Dataset):\n","    def __init__(self, inputs, targets):\n","        self.inputs = inputs\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","    def __getitem__(self, idx):\n","        input_sample = torch.tensor(self.inputs[idx])\n","        target_sample = torch.tensor(self.targets[idx])\n","\n","        sample = (input_sample, target_sample)\n","\n","        return sample"],"metadata":{"id":"7e4gegnfh9LN","executionInfo":{"status":"ok","timestamp":1702330919723,"user_tz":300,"elapsed":6,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["trainDataset = MyDataset(l[:,0], l[:,1])"],"metadata":{"id":"ZdxUaa2nh-32","executionInfo":{"status":"ok","timestamp":1702330921437,"user_tz":300,"elapsed":145,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["bs = 1024\n","#!cat models.py"],"metadata":{"id":"gaYidLv80OAk","executionInfo":{"status":"ok","timestamp":1702330922750,"user_tz":300,"elapsed":146,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","traindataloader = DataLoader(trainDataset, batch_size=bs, shuffle=True)\n","testdataloader = DataLoader(validDataset, batch_size=bs, shuffle=True)"],"metadata":{"id":"0IHuBP7miIvh","executionInfo":{"status":"ok","timestamp":1702330924280,"user_tz":300,"elapsed":150,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Transformer/seq+energy: 94.5%"],"metadata":{"id":"Ev2KzZJrAewn"}},{"cell_type":"code","execution_count":26,"metadata":{"id":"Tvr2BIh-rz0N","colab":{"base_uri":"https://localhost:8080/"},"outputId":"73ae580f-9ef7-4278-d7a5-a00b73045318","executionInfo":{"status":"ok","timestamp":1702331181239,"user_tz":300,"elapsed":177207,"user":{"displayName":"Paul Krupski","userId":"09242718268950552751"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-21-e968f9abd1eb>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  input_sample = torch.tensor(self.inputs[idx])\n","<ipython-input-21-e968f9abd1eb>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  target_sample = torch.tensor(self.targets[idx])\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Train Accuracy: 0.5001\n","Epoch [1/100], Test Accuracy: 0.0844\n","Epoch [2/100], Train Accuracy: 0.5000\n","Epoch [2/100], Test Accuracy: 0.0844\n","Epoch [3/100], Train Accuracy: 0.5000\n","Epoch [3/100], Test Accuracy: 0.0844\n","Epoch [4/100], Train Accuracy: 0.5000\n","Epoch [4/100], Test Accuracy: 0.0844\n","Epoch [5/100], Train Accuracy: 0.5000\n","Epoch [5/100], Test Accuracy: 0.0844\n","Epoch [6/100], Train Accuracy: 0.5000\n","Epoch [6/100], Test Accuracy: 0.0844\n","Epoch [7/100], Train Accuracy: 0.5000\n","Epoch [7/100], Test Accuracy: 0.0844\n","Epoch [8/100], Train Accuracy: 0.5000\n","Epoch [8/100], Test Accuracy: 0.0844\n","Epoch [9/100], Train Accuracy: 0.5000\n","Epoch [9/100], Test Accuracy: 0.0844\n","Epoch [10/100], Train Accuracy: 0.5003\n","Epoch [10/100], Test Accuracy: 0.0846\n","Epoch [11/100], Train Accuracy: 0.5003\n","Epoch [11/100], Test Accuracy: 0.0846\n","Epoch [12/100], Train Accuracy: 0.5003\n","Epoch [12/100], Test Accuracy: 0.0847\n","Epoch [13/100], Train Accuracy: 0.5004\n","Epoch [13/100], Test Accuracy: 0.0846\n","Epoch [14/100], Train Accuracy: 0.5007\n","Epoch [14/100], Test Accuracy: 0.0846\n","Epoch [15/100], Train Accuracy: 0.5005\n","Epoch [15/100], Test Accuracy: 0.0849\n","Epoch [16/100], Train Accuracy: 0.5006\n","Epoch [16/100], Test Accuracy: 0.0847\n","Epoch [17/100], Train Accuracy: 0.5009\n","Epoch [17/100], Test Accuracy: 0.0848\n","Epoch [18/100], Train Accuracy: 0.5008\n","Epoch [18/100], Test Accuracy: 0.0851\n","Epoch [19/100], Train Accuracy: 0.5009\n","Epoch [19/100], Test Accuracy: 0.0857\n","Epoch [20/100], Train Accuracy: 0.5011\n","Epoch [20/100], Test Accuracy: 0.0860\n","Epoch [21/100], Train Accuracy: 0.5011\n","Epoch [21/100], Test Accuracy: 0.0856\n","Epoch [22/100], Train Accuracy: 0.5010\n","Epoch [22/100], Test Accuracy: 0.0851\n","Epoch [23/100], Train Accuracy: 0.5013\n","Epoch [23/100], Test Accuracy: 0.0853\n","Epoch [24/100], Train Accuracy: 0.5012\n","Epoch [24/100], Test Accuracy: 0.0854\n","Epoch [25/100], Train Accuracy: 0.5017\n","Epoch [25/100], Test Accuracy: 0.0854\n","Epoch [26/100], Train Accuracy: 0.5017\n","Epoch [26/100], Test Accuracy: 0.0862\n","Epoch [27/100], Train Accuracy: 0.5017\n","Epoch [27/100], Test Accuracy: 0.0861\n","Epoch [28/100], Train Accuracy: 0.5019\n","Epoch [28/100], Test Accuracy: 0.0854\n","Epoch [29/100], Train Accuracy: 0.5022\n","Epoch [29/100], Test Accuracy: 0.0869\n","Epoch [30/100], Train Accuracy: 0.5021\n","Epoch [30/100], Test Accuracy: 0.0852\n","Epoch [31/100], Train Accuracy: 0.5028\n","Epoch [31/100], Test Accuracy: 0.0856\n","Epoch [32/100], Train Accuracy: 0.5030\n","Epoch [32/100], Test Accuracy: 0.0857\n","Epoch [33/100], Train Accuracy: 0.5034\n","Epoch [33/100], Test Accuracy: 0.0855\n","Epoch [34/100], Train Accuracy: 0.5034\n","Epoch [34/100], Test Accuracy: 0.0851\n","Epoch [35/100], Train Accuracy: 0.5034\n","Epoch [35/100], Test Accuracy: 0.0868\n","Epoch [36/100], Train Accuracy: 0.5032\n","Epoch [36/100], Test Accuracy: 0.0857\n","Epoch [37/100], Train Accuracy: 0.5035\n","Epoch [37/100], Test Accuracy: 0.0863\n","Epoch [38/100], Train Accuracy: 0.5041\n","Epoch [38/100], Test Accuracy: 0.0860\n","Epoch [39/100], Train Accuracy: 0.5043\n","Epoch [39/100], Test Accuracy: 0.0857\n","Epoch [40/100], Train Accuracy: 0.5049\n","Epoch [40/100], Test Accuracy: 0.0861\n","Epoch [41/100], Train Accuracy: 0.5046\n","Epoch [41/100], Test Accuracy: 0.0855\n","Epoch [42/100], Train Accuracy: 0.5035\n","Epoch [42/100], Test Accuracy: 0.0868\n","Epoch [43/100], Train Accuracy: 0.5043\n","Epoch [43/100], Test Accuracy: 0.0861\n","Epoch [44/100], Train Accuracy: 0.5050\n","Epoch [44/100], Test Accuracy: 0.0866\n","Epoch [45/100], Train Accuracy: 0.5051\n","Epoch [45/100], Test Accuracy: 0.0856\n","Epoch [46/100], Train Accuracy: 0.5055\n","Epoch [46/100], Test Accuracy: 0.0856\n","Epoch [47/100], Train Accuracy: 0.5055\n","Epoch [47/100], Test Accuracy: 0.0864\n","Epoch [48/100], Train Accuracy: 0.5046\n","Epoch [48/100], Test Accuracy: 0.0864\n","Epoch [49/100], Train Accuracy: 0.5055\n","Epoch [49/100], Test Accuracy: 0.0865\n","Epoch [50/100], Train Accuracy: 0.5056\n","Epoch [50/100], Test Accuracy: 0.0871\n","Epoch [51/100], Train Accuracy: 0.5056\n","Epoch [51/100], Test Accuracy: 0.0874\n","Epoch [52/100], Train Accuracy: 0.5054\n","Epoch [52/100], Test Accuracy: 0.0858\n","Epoch [53/100], Train Accuracy: 0.5056\n","Epoch [53/100], Test Accuracy: 0.0867\n","Epoch [54/100], Train Accuracy: 0.5060\n","Epoch [54/100], Test Accuracy: 0.0863\n","Epoch [55/100], Train Accuracy: 0.5059\n","Epoch [55/100], Test Accuracy: 0.0868\n","Epoch [56/100], Train Accuracy: 0.5058\n","Epoch [56/100], Test Accuracy: 0.0869\n","Epoch [57/100], Train Accuracy: 0.5062\n","Epoch [57/100], Test Accuracy: 0.0861\n","Epoch [58/100], Train Accuracy: 0.5059\n","Epoch [58/100], Test Accuracy: 0.0858\n","Epoch [59/100], Train Accuracy: 0.5062\n","Epoch [59/100], Test Accuracy: 0.0872\n","Epoch [60/100], Train Accuracy: 0.5058\n","Epoch [60/100], Test Accuracy: 0.0861\n","Epoch [61/100], Train Accuracy: 0.5062\n","Epoch [61/100], Test Accuracy: 0.0870\n","Epoch [62/100], Train Accuracy: 0.5065\n","Epoch [62/100], Test Accuracy: 0.0868\n","Epoch [63/100], Train Accuracy: 0.5066\n","Epoch [63/100], Test Accuracy: 0.0869\n","Epoch [64/100], Train Accuracy: 0.5064\n","Epoch [64/100], Test Accuracy: 0.0864\n","Epoch [65/100], Train Accuracy: 0.5064\n","Epoch [65/100], Test Accuracy: 0.0870\n","Epoch [66/100], Train Accuracy: 0.5063\n","Epoch [66/100], Test Accuracy: 0.0869\n","Epoch [67/100], Train Accuracy: 0.5066\n","Epoch [67/100], Test Accuracy: 0.0866\n","Epoch [68/100], Train Accuracy: 0.5063\n","Epoch [68/100], Test Accuracy: 0.0865\n","Epoch [69/100], Train Accuracy: 0.5067\n","Epoch [69/100], Test Accuracy: 0.0865\n","Epoch [70/100], Train Accuracy: 0.5065\n","Epoch [70/100], Test Accuracy: 0.0869\n","Epoch [71/100], Train Accuracy: 0.5066\n","Epoch [71/100], Test Accuracy: 0.0864\n","Epoch [72/100], Train Accuracy: 0.5068\n","Epoch [72/100], Test Accuracy: 0.0867\n","Epoch [73/100], Train Accuracy: 0.5061\n","Epoch [73/100], Test Accuracy: 0.0867\n","Epoch [74/100], Train Accuracy: 0.5066\n","Epoch [74/100], Test Accuracy: 0.0862\n","Epoch [75/100], Train Accuracy: 0.5067\n","Epoch [75/100], Test Accuracy: 0.0875\n","Epoch [76/100], Train Accuracy: 0.5064\n","Epoch [76/100], Test Accuracy: 0.0873\n","Epoch [77/100], Train Accuracy: 0.5064\n","Epoch [77/100], Test Accuracy: 0.0863\n","Epoch [78/100], Train Accuracy: 0.5063\n","Epoch [78/100], Test Accuracy: 0.0869\n","Epoch [79/100], Train Accuracy: 0.5061\n","Epoch [79/100], Test Accuracy: 0.0868\n","Epoch [80/100], Train Accuracy: 0.5063\n","Epoch [80/100], Test Accuracy: 0.0870\n","Epoch [81/100], Train Accuracy: 0.5067\n","Epoch [81/100], Test Accuracy: 0.0869\n","Epoch [82/100], Train Accuracy: 0.5067\n","Epoch [82/100], Test Accuracy: 0.0856\n","Epoch [83/100], Train Accuracy: 0.5068\n","Epoch [83/100], Test Accuracy: 0.0861\n","Epoch [84/100], Train Accuracy: 0.5068\n","Epoch [84/100], Test Accuracy: 0.0868\n","Epoch [85/100], Train Accuracy: 0.5068\n","Epoch [85/100], Test Accuracy: 0.0867\n","Epoch [86/100], Train Accuracy: 0.5069\n","Epoch [86/100], Test Accuracy: 0.0865\n","Epoch [87/100], Train Accuracy: 0.5067\n","Epoch [87/100], Test Accuracy: 0.0864\n","Epoch [88/100], Train Accuracy: 0.5066\n","Epoch [88/100], Test Accuracy: 0.0868\n","Epoch [89/100], Train Accuracy: 0.5056\n","Epoch [89/100], Test Accuracy: 0.0860\n","Epoch [90/100], Train Accuracy: 0.5055\n","Epoch [90/100], Test Accuracy: 0.0876\n","Epoch [91/100], Train Accuracy: 0.5056\n","Epoch [91/100], Test Accuracy: 0.0858\n","Epoch [92/100], Train Accuracy: 0.5065\n","Epoch [92/100], Test Accuracy: 0.0863\n","Epoch [93/100], Train Accuracy: 0.5069\n","Epoch [93/100], Test Accuracy: 0.0866\n","Epoch [94/100], Train Accuracy: 0.5069\n","Epoch [94/100], Test Accuracy: 0.0872\n","Epoch [95/100], Train Accuracy: 0.5070\n","Epoch [95/100], Test Accuracy: 0.0871\n","Epoch [96/100], Train Accuracy: 0.5069\n","Epoch [96/100], Test Accuracy: 0.0866\n","Epoch [97/100], Train Accuracy: 0.5069\n","Epoch [97/100], Test Accuracy: 0.0866\n","Epoch [98/100], Train Accuracy: 0.5070\n","Epoch [98/100], Test Accuracy: 0.0865\n","Epoch [99/100], Train Accuracy: 0.5069\n","Epoch [99/100], Test Accuracy: 0.0864\n","Epoch [100/100], Train Accuracy: 0.5069\n","Epoch [100/100], Test Accuracy: 0.0869\n"]}],"source":["from models import TwoLayerNet, ThreeLayerNet, LinearRegressionModel, ConvolutionalNet, CRNNCrisprModel\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","\n","dim = 512\n","heads = 4\n","layers = 2\n","num_epochs = 100\n","\n","lossf = nn.BCELoss() #nn.CrossEntropyLoss()\n","#model = CRNNCrisprModel(False, None, 208, 256, 1)\n","#model = ConvolutionalNet(False)\n","model = ThreeLayerNet(208, 256, 1)\n","#model = TwoLayerNet(139, 256, 1)\n","#model = LinearRegressionModel(139, 256) RuntimeError: shape '[1, 60000]' is invalid for input of size 15360000\n","\n","'''encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dropout = 0.1)\n","transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=layers)\n","\n","model = nn.Sequential(\n","    nn.Linear(139,dim),\n","    transformer_encoder,\n","    nn.Linear(dim, 1),\n","    nn.Sigmoid()\n",")'''\n","\n","lrate = 0.001\n","\n","optimizer = optim.Adam(model.parameters(), lr=lrate)\n","\n","for epoch in range(num_epochs):\n","\n","    model.train()\n","\n","    total_correct = 0\n","    total_samples = 0\n","\n","    for batch in traindataloader:\n","        inputs, targets = batch\n","        # Forward pass\n","\n","        outputs = model(inputs).squeeze()\n","\n","        pred = outputs.detach().numpy()\n","        labels = targets.numpy()\n","\n","        # Assuming labels are in the range [0, 1] (0 for class 0, 1 for class 1)\n","        #labels = labels.float().view(-1, 1)  # Ensure labels are of type float and have shape (batch_size, 1)\n","\n","        # Compute accuracy\n","        predictions = pred > 0.5 #pred[:,1] > 0.5  # Threshold at 0.5 for binary classification\n","\n","        correct = np.sum(predictions == labels.astype(int))\n","        total_correct += correct\n","        total_samples += len(labels)\n","\n","        # Compute loss\n","        loss = lossf(outputs, targets)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {total_correct/total_samples:.4f}')\n","\n","    model.eval()  # Set the model to evaluation mode\n","    total_correct = 0\n","    total_samples = 0\n","\n","\n","    with torch.no_grad():  # Disable gradient computation during validation\n","        for batch in testdataloader:\n","            inputs, targets, extra = batch\n","            outputs = model(inputs).squeeze()\n","\n","            #outputs = F.softmax(outputs, dim=1)\n","\n","            pred = outputs.numpy()\n","            labels = targets.numpy()\n","\n","            # Assuming labels are in the range [0, 1] (0 for class 0, 1 for class 1)\n","            #labels = labels.float().view(-1, 1)  # Ensure labels are of type float and have shape (batch_size, 1)\n","\n","            # Compute accuracy\n","            predictions = pred > 0.5 #pred[:,1] > 0.5  # Threshold at 0.5 for binary classification\n","\n","            correct = np.sum(predictions == labels.astype(int))\n","            total_correct += correct\n","            total_samples += len(labels)\n","\n","\n","    #accuracy = total_correct / total_samples\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Test Accuracy: {total_correct/total_samples:.4f}')\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"FaJjwAbs7t0E"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}